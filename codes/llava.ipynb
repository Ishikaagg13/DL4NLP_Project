{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HamzaKhalid\\envs\\heart\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for bitsandbytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlavaNextForConditionalGeneration, BitsAndBytesConfig\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# specify how to quantize the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mBitsAndBytesConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_quant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnf4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_compute_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# model = LlavaNextForConditionalGeneration.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\", quantization_config=quantization_config, device_map=\"auto\")\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Use Flash-Attention 2 to further speed-up generation\u001b[39;00m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m LlavaForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m, quantization_config\u001b[38;5;241m=\u001b[39mquantization_config, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HamzaKhalid\\envs\\heart\\lib\\site-packages\\transformers\\utils\\quantization_config.py:284\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.__init__\u001b[1;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    282\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnused kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. These kwargs are not used in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HamzaKhalid\\envs\\heart\\lib\\site-packages\\transformers\\utils\\quantization_config.py:342\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.post_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_4bit_use_double_quant, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbnb_4bit_use_double_quant must be a boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_in_4bit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbitsandbytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.39.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m ):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4 bit quantization requires bitsandbytes>=0.39.0 - please upgrade your bitsandbytes version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    347\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:955\u001b[0m, in \u001b[0;36mversion\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[0;32m    949\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \n\u001b[0;32m    951\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:928\u001b[0m, in \u001b[0;36mdistribution\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[0;32m    923\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \n\u001b[0;32m    925\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:518\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dist\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import requests\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from transformers import LlavaNextForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "# specify how to quantize the model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# model = LlavaNextForConditionalGeneration.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\", quantization_config=quantization_config, device_map=\"auto\")\n",
    "# Use Flash-Attention 2 to further speed-up generation\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\", quantization_config=quantization_config, device_map=\"auto\")\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "prompt = \"USER: <image>\\nWhat's the content of the image? ASSISTANT:\"\n",
    "\n",
    "\n",
    "url = \"https://nationalmuseumindia.gov.in/uploads/collections/1618479795_Toy%20Cart.jpg\"\n",
    "\n",
    "\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "# Generate\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=15)\n",
    "processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "     ---------------------------------------- 0.0/138.0 kB ? eta -:--:--\n",
      "     ------------------------------- ------ 112.6/138.0 kB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 138.0/138.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.4.16-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hamzakhalid\\envs\\heart\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "   ---------------------------------------- 0.0/9.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.0 MB 5.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/9.0 MB 5.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/9.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/9.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.5/9.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.0 MB 7.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.1/9.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.4/9.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.9/9.0 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.2/9.0 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.6/9.0 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.0/9.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.3/9.0 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.1/9.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.4/9.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.7/9.0 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.1/9.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.4/9.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/9.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.2/9.0 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.1/9.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.4/9.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.8/9.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.0/9.0 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 388.9/388.9 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl (145 kB)\n",
      "   ---------------------------------------- 0.0/145.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 145.3/145.3 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp310-cp310-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.9/268.9 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.4/287.4 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.4/2.2 MB 24.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.22.2 pyyaml-6.0.1 regex-2024.4.16 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
